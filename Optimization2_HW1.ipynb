{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifVOBwfGBbfZ"
   },
   "outputs": [],
   "source": [
    "# !pip install pyyaml h5py\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZO4rlhiB4Gz"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-iy9-ReCCf8",
    "outputId": "db77b170-24d0-4a88-b9ba-34d181fd26c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(7)\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "ndata_train = x_train.shape[0]\n",
    "ndata_test = x_test.shape[0]\n",
    "\n",
    "\n",
    "x_train = x_train.reshape((ndata_train,28,28,1))\n",
    "x_test = x_test.reshape((ndata_test,28,28,1))\n",
    "\n",
    "xshape = x_train.shape[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_1uT3HVDTNG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQ4FM5isCFSt"
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "# Convolutional layer 1\n",
    "model1.add(Conv2D(filters = 16, kernel_size = (2,2), input_shape=xshape, activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides = 1))\n",
    "\n",
    "# Convolutional layer 2\n",
    "model1.add(Conv2D(32,(2,2), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides = 1))\n",
    "\n",
    "# Convolutional layer 3\n",
    "model1.add(Conv2D(64,(2,2), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides = 1))\n",
    "\n",
    "\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "# Feedforward\n",
    "model1.add(Dense(units= 128, activation='relu'))\n",
    "model1.add(Dropout(0.1))\n",
    "model1.add(Dense(units= 128, activation='relu'))\n",
    "# model1.add(Dropout(0.1))\n",
    "model1.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, decay=0.0001, clipvalue=0.5)\n",
    "\n",
    "model1.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',\n",
    "                   metrics= ['accuracy'])\n",
    "\n",
    "model1_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)\n",
    "model1_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)\n",
    "model1_mcp = ModelCheckpoint(filepath = r'temp\\model1_weights.h5', monitor = 'accuracy',\n",
    "                             save_best_only = True, verbose = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MLLp37AD6_S",
    "outputId": "30e82af2-97a8-4a42-ebc0-0f821a049015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6642 - accuracy: 0.7971\n",
      "Epoch 00001: accuracy improved from -inf to 0.79715, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 14s 63ms/step - loss: 0.6642 - accuracy: 0.7971 - val_loss: 0.1997 - val_accuracy: 0.9408 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.9507\n",
      "Epoch 00002: accuracy improved from 0.79715 to 0.95075, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.1633 - accuracy: 0.9507 - val_loss: 0.0893 - val_accuracy: 0.9743 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9731\n",
      "Epoch 00003: accuracy improved from 0.95075 to 0.97315, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.0894 - accuracy: 0.9731 - val_loss: 0.0628 - val_accuracy: 0.9813 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9806\n",
      "Epoch 00004: accuracy improved from 0.97315 to 0.98065, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 62ms/step - loss: 0.0646 - accuracy: 0.9806 - val_loss: 0.0562 - val_accuracy: 0.9836 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9826\n",
      "Epoch 00005: accuracy improved from 0.98065 to 0.98258, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 60ms/step - loss: 0.0558 - accuracy: 0.9826 - val_loss: 0.0554 - val_accuracy: 0.9836 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9863\n",
      "Epoch 00006: accuracy improved from 0.98258 to 0.98633, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.0448 - accuracy: 0.9863 - val_loss: 0.0450 - val_accuracy: 0.9871 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9882\n",
      "Epoch 00007: accuracy improved from 0.98633 to 0.98819, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.0374 - accuracy: 0.9882 - val_loss: 0.0437 - val_accuracy: 0.9867 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9901\n",
      "Epoch 00008: accuracy improved from 0.98819 to 0.99013, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.0326 - accuracy: 0.9901 - val_loss: 0.0416 - val_accuracy: 0.9872 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9915\n",
      "Epoch 00009: accuracy improved from 0.99013 to 0.99148, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.0395 - val_accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9927\n",
      "Epoch 00010: accuracy improved from 0.99148 to 0.99275, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 62ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.0394 - val_accuracy: 0.9883 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9933\n",
      "Epoch 00011: accuracy improved from 0.99275 to 0.99327, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0393 - val_accuracy: 0.9895 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9942\n",
      "Epoch 00012: accuracy improved from 0.99327 to 0.99417, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.0382 - val_accuracy: 0.9895 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9943\n",
      "Epoch 00013: accuracy improved from 0.99417 to 0.99433, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 72ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0396 - val_accuracy: 0.9884 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9947\n",
      "Epoch 00014: accuracy improved from 0.99433 to 0.99473, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.0370 - val_accuracy: 0.9889 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9955\n",
      "Epoch 00015: accuracy improved from 0.99473 to 0.99546, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.0388 - val_accuracy: 0.9889 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9961\n",
      "Epoch 00016: accuracy improved from 0.99546 to 0.99610, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0373 - val_accuracy: 0.9902 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9964\n",
      "Epoch 00017: accuracy improved from 0.99610 to 0.99642, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.0399 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9967\n",
      "Epoch 00018: accuracy improved from 0.99642 to 0.99667, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0369 - val_accuracy: 0.9893 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9975\n",
      "Epoch 00019: accuracy improved from 0.99667 to 0.99750, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.0387 - val_accuracy: 0.9896 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9974\n",
      "Epoch 00020: accuracy did not improve from 0.99750\n",
      "48/48 [==============================] - 3s 62ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0416 - val_accuracy: 0.9877 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9976\n",
      "Epoch 00021: accuracy improved from 0.99750 to 0.99765, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0413 - val_accuracy: 0.9889 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9979\n",
      "Epoch 00022: accuracy improved from 0.99765 to 0.99787, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0407 - val_accuracy: 0.9899 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9975\n",
      "Epoch 00023: accuracy did not improve from 0.99787\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0407 - val_accuracy: 0.9905 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9985\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00024: accuracy improved from 0.99787 to 0.99846, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0423 - val_accuracy: 0.9894 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 00025: accuracy improved from 0.99846 to 0.99923, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0383 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 00026: accuracy did not improve from 0.99923\n",
      "48/48 [==============================] - 3s 61ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0389 - val_accuracy: 0.9903 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 00027: accuracy improved from 0.99923 to 0.99937, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0393 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 00028: accuracy did not improve from 0.99937\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0390 - val_accuracy: 0.9903 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 00029: accuracy did not improve from 0.99937\n",
      "48/48 [==============================] - 3s 61ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0406 - val_accuracy: 0.9900 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "\n",
      "Epoch 00030: accuracy improved from 0.99937 to 0.99944, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0403 - val_accuracy: 0.9903 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 00031: accuracy improved from 0.99944 to 0.99950, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0401 - val_accuracy: 0.9900 - lr: 2.0000e-05\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 00032: accuracy improved from 0.99950 to 0.99952, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0400 - val_accuracy: 0.9902 - lr: 2.0000e-05\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 00033: accuracy did not improve from 0.99952\n",
      "48/48 [==============================] - 3s 60ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0402 - val_accuracy: 0.9902 - lr: 2.0000e-05\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 00034: accuracy improved from 0.99952 to 0.99958, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0398 - val_accuracy: 0.9902 - lr: 2.0000e-05\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9996\n",
      "Epoch 00035: accuracy did not improve from 0.99958\n",
      "48/48 [==============================] - 3s 60ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0398 - val_accuracy: 0.9901 - lr: 2.0000e-05\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "\n",
      "Epoch 00036: accuracy improved from 0.99958 to 0.99960, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0399 - val_accuracy: 0.9903 - lr: 2.0000e-05\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9998\n",
      "Epoch 00037: accuracy improved from 0.99960 to 0.99975, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0398 - val_accuracy: 0.9902 - lr: 4.0000e-06\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 00038: accuracy improved from 0.99975 to 0.99977, saving model to temp\\model1_weights.h5\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0398 - val_accuracy: 0.9902 - lr: 4.0000e-06\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 00039: accuracy did not improve from 0.99977\n",
      "48/48 [==============================] - 3s 60ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0398 - val_accuracy: 0.9903 - lr: 4.0000e-06\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 00040: accuracy did not improve from 0.99977\n",
      "48/48 [==============================] - 3s 60ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0397 - val_accuracy: 0.9903 - lr: 4.0000e-06\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9996\n",
      "Epoch 00041: accuracy did not improve from 0.99977\n",
      "48/48 [==============================] - 3s 60ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0398 - val_accuracy: 0.9903 - lr: 4.0000e-06\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.99977\n",
      "48/48 [==============================] - 3s 62ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0397 - val_accuracy: 0.9902 - lr: 4.0000e-06\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 00043: accuracy did not improve from 0.99977\n",
      "48/48 [==============================] - 3s 61ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0397 - val_accuracy: 0.9902 - lr: 8.0000e-07\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9996\n",
      "Epoch 00044: accuracy did not improve from 0.99977\n",
      "48/48 [==============================] - 3s 62ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0398 - val_accuracy: 0.9902 - lr: 8.0000e-07\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9997\n",
      "Epoch 00045: accuracy did not improve from 0.99977\n",
      "48/48 [==============================] - 3s 61ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0398 - val_accuracy: 0.9902 - lr: 8.0000e-07\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9996\n",
      "Epoch 00046: accuracy did not improve from 0.99977\n",
      "48/48 [==============================] - 3s 60ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0398 - val_accuracy: 0.9902 - lr: 8.0000e-07\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 00047: accuracy did not improve from 0.99977\n",
      "48/48 [==============================] - 3s 62ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0398 - val_accuracy: 0.9902 - lr: 8.0000e-07\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.6000001323845936e-07.\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.99977\n",
      "48/48 [==============================] - 3s 61ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0398 - val_accuracy: 0.9902 - lr: 8.0000e-07\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9997\n",
      "Epoch 00049: accuracy did not improve from 0.99977\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0398 - val_accuracy: 0.9902 - lr: 1.6000e-07\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 00050: accuracy did not improve from 0.99977\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0398 - val_accuracy: 0.9902 - lr: 1.6000e-07\n",
      "Epoch 00050: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(x_train,y_train,epochs=100,validation_split=0.2,batch_size=1000, callbacks=[model1_es, model1_rlr, model1_mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6KPGzqGnE56w",
    "outputId": "4ffde7a5-227c-4405-bef3-9ae028d4892f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 0.0310 - accuracy: 0.9918\n",
      "This model predicts 99.18000102043152% of the test data correctly\n"
     ]
    }
   ],
   "source": [
    "print('This model predicts '+str(model1.evaluate(x_test,y_test)[1]*100) +'% of the test data correctly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GyduupRoiUNV"
   },
   "outputs": [],
   "source": [
    "model1.save('my_model.h5') \n",
    "model1 = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPtvo_aWHwuH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9L3h47tLj0hw",
    "outputId": "35ca7d9b-8db4-4502-d2b8-2790120b94ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5433 - accuracy: 0.8344WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.83437, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 4s 58ms/step - loss: 0.5433 - accuracy: 0.8344 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9647WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.83437 to 0.96467, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.1176 - accuracy: 0.9647 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9780WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.96467 to 0.97805, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 0.0724 - accuracy: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9826WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.97805 to 0.98258, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 4s 58ms/step - loss: 0.0568 - accuracy: 0.9826 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9856WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.98258 to 0.98563, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 4s 60ms/step - loss: 0.0471 - accuracy: 0.9856 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9886WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00006: accuracy improved from 0.98563 to 0.98857, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 0.0383 - accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9898WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00007: accuracy improved from 0.98857 to 0.98982, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.0340 - accuracy: 0.9898 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9915WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00008: accuracy improved from 0.98982 to 0.99148, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.0290 - accuracy: 0.9915 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9916WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00009: accuracy improved from 0.99148 to 0.99165, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 0.0267 - accuracy: 0.9916 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9929WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00010: accuracy improved from 0.99165 to 0.99288, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.0227 - accuracy: 0.9929 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9938WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00011: accuracy improved from 0.99288 to 0.99378, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 4s 64ms/step - loss: 0.0207 - accuracy: 0.9938 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9944WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00012: accuracy improved from 0.99378 to 0.99435, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 4s 62ms/step - loss: 0.0188 - accuracy: 0.9944 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9951WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00013: accuracy improved from 0.99435 to 0.99513, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 0.0163 - accuracy: 0.9951 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9954WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00014: accuracy improved from 0.99513 to 0.99538, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 4s 60ms/step - loss: 0.0150 - accuracy: 0.9954 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9955WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00015: accuracy improved from 0.99538 to 0.99548, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 4s 62ms/step - loss: 0.0138 - accuracy: 0.9955 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9959WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00016: accuracy improved from 0.99548 to 0.99590, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 0.0123 - accuracy: 0.9959 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9959WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.99590\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.0121 - accuracy: 0.9959 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9966WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00018: accuracy improved from 0.99590 to 0.99663, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 0.0109 - accuracy: 0.9966 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9968WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00019: accuracy improved from 0.99663 to 0.99682, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 0.0100 - accuracy: 0.9968 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9976WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00020: accuracy improved from 0.99682 to 0.99757, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 0.0080 - accuracy: 0.9976 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9980WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00021: accuracy improved from 0.99757 to 0.99805, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.0068 - accuracy: 0.9980 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9985WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00022: accuracy improved from 0.99805 to 0.99855, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.0053 - accuracy: 0.9985 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9980WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.99855\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.0064 - accuracy: 0.9980 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9978WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.99855\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0068 - accuracy: 0.9978 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9979WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.99855\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.0065 - accuracy: 0.9979 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9982WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.99855\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.0060 - accuracy: 0.9982 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9984WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.99855\n",
      "60/60 [==============================] - 3s 54ms/step - loss: 0.0055 - accuracy: 0.9984 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9981WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.99855\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0055 - accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9987WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00029: accuracy improved from 0.99855 to 0.99865, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.0047 - accuracy: 0.9987 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9990WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00030: accuracy improved from 0.99865 to 0.99898, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.0037 - accuracy: 0.9990 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.99898\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0034 - accuracy: 0.9990 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9987WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.99898\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0037 - accuracy: 0.9987 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.99898\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0035 - accuracy: 0.9989 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9990WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.99898\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0035 - accuracy: 0.9990 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.99898\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0034 - accuracy: 0.9989 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.99898\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0035 - accuracy: 0.9989 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00037: accuracy improved from 0.99898 to 0.99933, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.0025 - accuracy: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.99933\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0025 - accuracy: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.99933\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0023 - accuracy: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.99933\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.0031 - accuracy: 0.9989 - lr: 5.0000e-04\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00041: accuracy improved from 0.99933 to 0.99955, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 4s 60ms/step - loss: 0.0017 - accuracy: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.99955\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.0028 - accuracy: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.99955\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0040 - accuracy: 0.9987 - lr: 5.0000e-04\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.99955\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0032 - accuracy: 0.9989 - lr: 5.0000e-04\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.99955\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0027 - accuracy: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.99955\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0030 - accuracy: 0.9990 - lr: 5.0000e-04\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9984WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.99955\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0046 - accuracy: 0.9984 - lr: 5.0000e-04\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9985WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.99955\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0039 - accuracy: 0.9985 - lr: 5.0000e-04\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.99955\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0020 - accuracy: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00050: accuracy improved from 0.99955 to 0.99973, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.0011 - accuracy: 0.9997 - lr: 5.0000e-04\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00051: accuracy did not improve from 0.99973\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0014 - accuracy: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00052: accuracy did not improve from 0.99973\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0016 - accuracy: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00053: accuracy did not improve from 0.99973\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.0022 - accuracy: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00054: accuracy did not improve from 0.99973\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0020 - accuracy: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00055: accuracy did not improve from 0.99973\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 0.0011 - accuracy: 0.9997 - lr: 5.0000e-04\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00056: accuracy did not improve from 0.99973\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0015 - accuracy: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00057: accuracy did not improve from 0.99973\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0021 - accuracy: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00058: accuracy did not improve from 0.99973\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.0016 - accuracy: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00059: accuracy did not improve from 0.99973\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0010 - accuracy: 0.9997 - lr: 5.0000e-04\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 9.3148e-04 - accuracy: 0.9998WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00060: accuracy improved from 0.99973 to 0.99977, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 9.3148e-04 - accuracy: 0.9998 - lr: 5.0000e-04\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00061: accuracy did not improve from 0.99977\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0026 - accuracy: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00062: accuracy did not improve from 0.99977\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0023 - accuracy: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00063: accuracy did not improve from 0.99977\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0025 - accuracy: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00064: accuracy did not improve from 0.99977\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0019 - accuracy: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 8.6849e-04 - accuracy: 0.9998WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00065: accuracy improved from 0.99977 to 0.99978, saving model to temp\\model1_weights.h5\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 8.6849e-04 - accuracy: 0.9998 - lr: 5.0000e-04\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00066: accuracy did not improve from 0.99978\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0011 - accuracy: 0.9997 - lr: 5.0000e-04\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00067: accuracy did not improve from 0.99978\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0013 - accuracy: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00068: accuracy did not improve from 0.99978\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0017 - accuracy: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00069: accuracy did not improve from 0.99978\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.0018 - accuracy: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00070: accuracy did not improve from 0.99978\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.0014 - accuracy: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00071: accuracy did not improve from 0.99978\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0011 - accuracy: 0.9997 - lr: 5.0000e-04\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00072: accuracy did not improve from 0.99978\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0016 - accuracy: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00073: accuracy did not improve from 0.99978\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0012 - accuracy: 0.9997 - lr: 5.0000e-04\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00074: accuracy did not improve from 0.99978\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0011 - accuracy: 0.9997 - lr: 5.0000e-04\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00075: accuracy did not improve from 0.99978\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.0012 - accuracy: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00076: accuracy did not improve from 0.99978\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.0013 - accuracy: 0.9997 - lr: 5.0000e-04\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00077: accuracy did not improve from 0.99978\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.0011 - accuracy: 0.9997 - lr: 5.0000e-04\n",
      "Epoch 00077: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Retraining with entire dataset using same model\n",
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "model2 = clone_model(model1)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, decay=0.0001, clipvalue=0.5)\n",
    "model2.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',\n",
    "                   metrics= ['accuracy'])\n",
    "\n",
    "model1_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)\n",
    "model1_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)\n",
    "model1_mcp = ModelCheckpoint(filepath = r'temp\\model1_weights.h5', monitor = 'accuracy',\n",
    "                             save_best_only = True, verbose = 1)\n",
    "\n",
    "history2 = model2.fit(x_train,y_train,epochs=100,validation_split=0.0,batch_size=1000, callbacks=[model1_es, model1_rlr, model1_mcp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSa5e9qak-Hi",
    "outputId": "e7336f0c-becc-4a14-ebca-e0b1b379f0c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0357 - accuracy: 0.9918\n",
      "This model predicts 99.18000102043152% of the test data correctly\n"
     ]
    }
   ],
   "source": [
    "print('This model predicts '+str(model2.evaluate(x_test,y_test)[1]*100) +'% of the test data correctly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mZiR5KDlEVf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhZ_g7Gb4EtJ"
   },
   "source": [
    "I am getting upwards of 99% accuracy after expirimenting with multiple model architectures and hyperparameters.  It would be rare to reach 100% accuracy as there is a possibility of numbers being mislabelled, or differences in handwriting making few numbers look very alike which the model is not able to pick.\n",
    "\n",
    "To increase the accuracy, model can be better tuned or an ensemble of muliple models can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9K5a6-rJ9gIc",
    "outputId": "761553df-8969-4cf0-8666-b63710097fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   actual  predicted\n",
      "0       7          7\n",
      "1       2          2\n",
      "2       1          1\n",
      "3       0          0\n",
      "4       4          4\n"
     ]
    }
   ],
   "source": [
    "df  = pd.DataFrame(index=[x for x in range(len(x_test)) ], columns = ['actual','predicted']).fillna(0)\n",
    "model_prediction = model2.predict(x_test)\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    df.loc[i,'actual'] = y_test[i]\n",
    "    df.loc[i,'predicted'] = np.argmax(model_prediction[i])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofkjIp1697KG",
    "outputId": "c5b5eeae-9630-423d-f600-cd8d5992843f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    23\n",
       "2    10\n",
       "6    10\n",
       "5     8\n",
       "8     8\n",
       "4     7\n",
       "1     4\n",
       "3     4\n",
       "7     4\n",
       "0     4\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MisClassifications \n",
    "# Index is the Number and Value is the amount of times it was misclassified\n",
    "df[df.actual != df.predicted]['actual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTa2L3MkAsqq",
    "outputId": "4457922d-3211-4897-b59e-299f84757433"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4    9\n",
       "7    7\n",
       "5    3\n",
       "1    2\n",
       "3    1\n",
       "8    1\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the Misclassified Number below\n",
    "misclass_num = 9\n",
    "\n",
    "df[df.actual != df.predicted][df.actual == misclass_num]['predicted'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRvquaS05EVN"
   },
   "source": [
    "What this means is the number 9 which was misclassified 23 times in test data set was read as 4 nine times, 7 seven times etc...\n",
    "\n",
    "This makes sense as 9 and 4 look kinda alike!!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Optimization2 - HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
